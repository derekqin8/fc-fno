{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f4ffba",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159b869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6481a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import h5py\n",
    "\n",
    "#################################################\n",
    "#\n",
    "# Utilities\n",
    "#\n",
    "#################################################\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# reading data\n",
    "class MatReader(object):\n",
    "    def __init__(self, file_path, to_torch=True, to_cuda=False, to_float=True):\n",
    "        super(MatReader, self).__init__()\n",
    "\n",
    "        self.to_torch = to_torch\n",
    "        self.to_cuda = to_cuda\n",
    "        self.to_float = to_float\n",
    "\n",
    "        self.file_path = file_path\n",
    "\n",
    "        self.data = None\n",
    "        self.old_mat = None\n",
    "        self._load_file()\n",
    "\n",
    "    def _load_file(self):\n",
    "        try:\n",
    "            self.data = scipy.io.loadmat(self.file_path)\n",
    "            self.old_mat = True\n",
    "        except:\n",
    "            self.data = h5py.File(self.file_path, 'r')\n",
    "            self.old_mat = False\n",
    "\n",
    "    def load_file(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self._load_file()\n",
    "\n",
    "    def read_field(self, field):\n",
    "        x = self.data[field]\n",
    "\n",
    "        if not self.old_mat:\n",
    "            x = x[()]\n",
    "            x = np.transpose(x, axes=range(len(x.shape) - 1, -1, -1))\n",
    "\n",
    "        if self.to_float:\n",
    "            x = x.astype(np.float32)\n",
    "\n",
    "        if self.to_torch:\n",
    "            x = torch.from_numpy(x)\n",
    "\n",
    "            if self.to_cuda:\n",
    "                x = x.cuda()\n",
    "\n",
    "        return x\n",
    "\n",
    "    def set_cuda(self, to_cuda):\n",
    "        self.to_cuda = to_cuda\n",
    "\n",
    "    def set_torch(self, to_torch):\n",
    "        self.to_torch = to_torch\n",
    "\n",
    "    def set_float(self, to_float):\n",
    "        self.to_float = to_float\n",
    "\n",
    "# normalization, pointwise gaussian\n",
    "class UnitGaussianNormalizer(object):\n",
    "    def __init__(self, x, eps=0.00001):\n",
    "        super(UnitGaussianNormalizer, self).__init__()\n",
    "\n",
    "        # x could be in shape of ntrain*n or ntrain*T*n or ntrain*n*T\n",
    "        self.mean = torch.mean(x, 0)\n",
    "        self.std = torch.std(x, 0)\n",
    "        self.eps = eps\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = (x - self.mean) / (self.std + self.eps)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, sample_idx=None):\n",
    "        if sample_idx is None:\n",
    "            std = self.std + self.eps # n\n",
    "            mean = self.mean\n",
    "        else:\n",
    "            if len(self.mean.shape) == len(sample_idx[0].shape):\n",
    "                std = self.std[sample_idx] + self.eps  # batch*n\n",
    "                mean = self.mean[sample_idx]\n",
    "            if len(self.mean.shape) > len(sample_idx[0].shape):\n",
    "                std = self.std[:,sample_idx]+ self.eps # T*batch*n\n",
    "                mean = self.mean[:,sample_idx]\n",
    "\n",
    "        # x is in shape of batch*n or T*batch*n\n",
    "        x = (x * std) + mean\n",
    "        return x\n",
    "\n",
    "    def cuda(self):\n",
    "        self.mean = self.mean.cuda()\n",
    "        self.std = self.std.cuda()\n",
    "\n",
    "    def cpu(self):\n",
    "        self.mean = self.mean.cpu()\n",
    "        self.std = self.std.cpu()\n",
    "\n",
    "# normalization, Gaussian\n",
    "class GaussianNormalizer(object):\n",
    "    def __init__(self, x, eps=0.00001):\n",
    "        super(GaussianNormalizer, self).__init__()\n",
    "\n",
    "        self.mean = torch.mean(x)\n",
    "        self.std = torch.std(x)\n",
    "        self.eps = eps\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = (x - self.mean) / (self.std + self.eps)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, sample_idx=None):\n",
    "        x = (x * (self.std + self.eps)) + self.mean\n",
    "        return x\n",
    "\n",
    "    def cuda(self):\n",
    "        self.mean = self.mean.cuda()\n",
    "        self.std = self.std.cuda()\n",
    "\n",
    "    def cpu(self):\n",
    "        self.mean = self.mean.cpu()\n",
    "        self.std = self.std.cpu()\n",
    "\n",
    "\n",
    "# normalization, scaling by range\n",
    "class RangeNormalizer(object):\n",
    "    def __init__(self, x, low=0.0, high=1.0):\n",
    "        super(RangeNormalizer, self).__init__()\n",
    "        mymin = torch.min(x, 0)[0].view(-1)\n",
    "        mymax = torch.max(x, 0)[0].view(-1)\n",
    "\n",
    "        self.a = (high - low)/(mymax - mymin)\n",
    "        self.b = -self.a*mymax + high\n",
    "\n",
    "    def encode(self, x):\n",
    "        s = x.size()\n",
    "        x = x.view(s[0], -1)\n",
    "        x = self.a*x + self.b\n",
    "        x = x.view(s)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        s = x.size()\n",
    "        x = x.view(s[0], -1)\n",
    "        x = (x - self.b)/self.a\n",
    "        x = x.view(s)\n",
    "        return x\n",
    "\n",
    "#loss function with rel/abs Lp loss\n",
    "class LpLoss(object):\n",
    "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
    "        super(LpLoss, self).__init__()\n",
    "\n",
    "        #Dimension and Lp-norm type are postive\n",
    "        assert d > 0 and p > 0\n",
    "\n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def abs(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        #Assume uniform mesh\n",
    "        h = 1.0 / (x.size()[1] - 1.0)\n",
    "\n",
    "        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(all_norms)\n",
    "            else:\n",
    "                return torch.sum(all_norms)\n",
    "\n",
    "        return all_norms\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
    "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms/y_norms)\n",
    "            else:\n",
    "                return torch.sum(diff_norms/y_norms)\n",
    "\n",
    "        return diff_norms/y_norms\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        return self.rel(x, y)\n",
    "\n",
    "# Sobolev norm (HS norm)\n",
    "# where we also compare the numerical derivatives between the output and target\n",
    "class HsLoss(object):\n",
    "    def __init__(self, d=2, p=2, k=1, a=None, group=False, size_average=True, reduction=True):\n",
    "        super(HsLoss, self).__init__()\n",
    "\n",
    "        #Dimension and Lp-norm type are postive\n",
    "        assert d > 0 and p > 0\n",
    "\n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.k = k\n",
    "        self.balanced = group\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average\n",
    "\n",
    "        if a == None:\n",
    "            a = [1,] * k\n",
    "        self.a = a\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
    "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms/y_norms)\n",
    "            else:\n",
    "                return torch.sum(diff_norms/y_norms)\n",
    "        return diff_norms/y_norms\n",
    "\n",
    "    def __call__(self, x, y, a=None):\n",
    "        nx = x.size()[1]\n",
    "        ny = x.size()[2]\n",
    "        k = self.k\n",
    "        balanced = self.balanced\n",
    "        a = self.a\n",
    "        x = x.view(x.shape[0], nx, ny, -1)\n",
    "        y = y.view(y.shape[0], nx, ny, -1)\n",
    "\n",
    "        k_x = torch.cat((torch.arange(start=0, end=nx//2, step=1),torch.arange(start=-nx//2, end=0, step=1)), 0).reshape(nx,1).repeat(1,ny)\n",
    "        k_y = torch.cat((torch.arange(start=0, end=ny//2, step=1),torch.arange(start=-ny//2, end=0, step=1)), 0).reshape(1,ny).repeat(nx,1)\n",
    "        k_x = torch.abs(k_x).reshape(1,nx,ny,1).to(x.device)\n",
    "        k_y = torch.abs(k_y).reshape(1,nx,ny,1).to(x.device)\n",
    "\n",
    "        x = torch.fft.fftn(x, dim=[1, 2])\n",
    "        y = torch.fft.fftn(y, dim=[1, 2])\n",
    "\n",
    "        if balanced==False:\n",
    "            weight = 1\n",
    "            if k >= 1:\n",
    "                weight += a[0]**2 * (k_x**2 + k_y**2)\n",
    "            if k >= 2:\n",
    "                weight += a[1]**2 * (k_x**4 + 2*k_x**2*k_y**2 + k_y**4)\n",
    "            weight = torch.sqrt(weight)\n",
    "            loss = self.rel(x*weight, y*weight)\n",
    "        else:\n",
    "            loss = self.rel(x, y)\n",
    "            if k >= 1:\n",
    "                weight = a[0] * torch.sqrt(k_x**2 + k_y**2)\n",
    "                loss += self.rel(x*weight, y*weight)\n",
    "            if k >= 2:\n",
    "                weight = a[1] * torch.sqrt(k_x**4 + 2*k_x**2*k_y**2 + k_y**4)\n",
    "                loss += self.rel(x*weight, y*weight)\n",
    "            loss = loss / (k+1)\n",
    "\n",
    "        return loss\n",
    "\n",
    "# A simple feedforward neural network\n",
    "class DenseNet(torch.nn.Module):\n",
    "    def __init__(self, layers, nonlinearity, out_nonlinearity=None, normalize=False):\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        self.n_layers = len(layers) - 1\n",
    "\n",
    "        assert self.n_layers >= 1\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for j in range(self.n_layers):\n",
    "            self.layers.append(nn.Linear(layers[j], layers[j+1]))\n",
    "\n",
    "            if j != self.n_layers - 1:\n",
    "                if normalize:\n",
    "                    self.layers.append(nn.BatchNorm1d(layers[j+1]))\n",
    "\n",
    "                self.layers.append(nonlinearity())\n",
    "\n",
    "        if out_nonlinearity is not None:\n",
    "            self.layers.append(out_nonlinearity())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for _, l in enumerate(self.layers):\n",
    "            x = l(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# print the number of parameters\n",
    "def count_params(model):\n",
    "    c = 0\n",
    "    for p in list(model.parameters()):\n",
    "        c += reduce(operator.mul, list(p.size()))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc040d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n",
    "        super(SpectralConv3d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        3D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights3 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights4 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul3d(self, input, weights):\n",
    "        # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
    "        return torch.einsum(\"bixyz,ioxyz->boxyz\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfftn(x, dim=[-3,-2,-1])\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-3), x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n",
    "        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n",
    "        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8895bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO3d(nn.Module):\n",
    "    def __init__(self, modes1, modes2, modes3, width):\n",
    "        super(FNO3d, self).__init__()\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        input: the solution of the first 10 timesteps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t). It's a constant function in time, except for the last index.\n",
    "        input shape: (batchsize, x=64, y=64, t=40, c=13)\n",
    "        output: the solution of the next 40 timesteps\n",
    "        output shape: (batchsize, x=64, y=64, t=40, c=1)\n",
    "        \"\"\"\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "        self.width = width\n",
    "        self.fc0 = nn.Linear(13, self.width)\n",
    "        # input channel is 12: the solution of the first 10 timesteps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t)\n",
    "        self.conv0 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv1 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv2 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv3 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.bn0 = torch.nn.BatchNorm3d(self.width, track_running_stats=False)\n",
    "        self.bn1 = torch.nn.BatchNorm3d(self.width, track_running_stats=False)\n",
    "        self.bn2 = torch.nn.BatchNorm3d(self.width, track_running_stats=False)\n",
    "        self.bn3 = torch.nn.BatchNorm3d(self.width, track_running_stats=False)\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        size_x, size_y, size_z = x.shape[1], x.shape[2], x.shape[3]\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 4, 1, 2, 3)\n",
    "        x1 = self.conv0(x)\n",
    "        x1 = self.bn0(x1)\n",
    "        x2 = self.w0(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x)\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.bn1(x1)\n",
    "        x2 = self.w1(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x)\n",
    "        x1 = self.conv2(x)\n",
    "        x1 = self.bn2(x1)\n",
    "        x2 = self.w2(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x)\n",
    "        x1 = self.conv3(x)\n",
    "        x1 = self.bn3(x1)\n",
    "        x2 = self.w3(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
    "        x = x1 + x2\n",
    "        x = x.permute(0, 2, 3, 4, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585f4991",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25aabf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 600\n",
    "ntest = 200\n",
    "\n",
    "sample_rate = 1\n",
    "S = 64 // sample_rate\n",
    "\n",
    "sample_rate_t = 1\n",
    "T = 50 // sample_rate_t\n",
    "\n",
    "T_in = 10\n",
    "\n",
    "max_pad = 21\n",
    "\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "epochs = 100\n",
    "step_size = 20\n",
    "gamma = 0.5\n",
    "\n",
    "modes = 8\n",
    "width = 20\n",
    "\n",
    "num_runs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b031763",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b848a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 64, 64, 10])\n",
      "torch.Size([5000, 64, 64, 40])\n",
      "torch.Size([600, 64, 64, 10])\n",
      "torch.Size([600, 64, 64, 40])\n",
      "torch.Size([200, 64, 64, 10])\n",
      "torch.Size([200, 64, 64, 40])\n"
     ]
    }
   ],
   "source": [
    "data_loader = MatReader('ns_V1e-3_N5000_T50.mat')\n",
    "\n",
    "x_data_raw = data_loader.read_field('u')[:,::sample_rate,::sample_rate,:T_in]\n",
    "y_data_raw = data_loader.read_field('u')[:,::sample_rate,::sample_rate,T_in:]\n",
    "\n",
    "print(x_data_raw.shape)\n",
    "print(y_data_raw.shape)\n",
    "\n",
    "x_train = x_data_raw[:ntrain]\n",
    "y_train = y_data_raw[:ntrain]\n",
    "\n",
    "x_test = x_data_raw[ntrain:ntrain+ntest]\n",
    "y_test = y_data_raw[ntrain:ntrain+ntest]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "del x_data_raw\n",
    "del y_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f19bf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600, 64, 64, 40, 10])\n",
      "torch.Size([200, 64, 64, 40, 10])\n"
     ]
    }
   ],
   "source": [
    "x_normalizer = UnitGaussianNormalizer(x_train)\n",
    "x_train = x_normalizer.encode(x_train)\n",
    "x_test = x_normalizer.encode(x_test)\n",
    "\n",
    "y_normalizer = UnitGaussianNormalizer(y_train)\n",
    "y_train = y_normalizer.encode(y_train)\n",
    "y_test = y_normalizer.encode(y_test)\n",
    "\n",
    "x_train = x_train.reshape(ntrain, S, S, 1, T_in).repeat([1,1,1,T-T_in,1])\n",
    "x_test = x_test.reshape(ntest, S, S, 1, T_in).repeat([1,1,1,T-T_in,1])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc8422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad2D(x_in_train, x_in_test, pad_size):\n",
    "#     padx_train = torch.zeros((ntrain, pad_size, data_points, time_points, time_in))\n",
    "#     x_train_pad = torch.cat([padx_train, x_train, padx_train], 1)\n",
    "    \n",
    "#     print(x_train_pad.shape)\n",
    "    \n",
    "#     pady_train = torch.zeros((ntrain, data_points + 2*pad_size, pad_size, time_points, time_in))\n",
    "#     x_train_pad = torch.cat([pady_train, x_train_pad, pady_train], 2)\n",
    "    \n",
    "#     print(x_train_pad.shape)\n",
    "    \n",
    "#     padx_test = torch.zeros((ntest, pad_size, data_points, time_points, time_in))\n",
    "#     x_test_pad = torch.cat([padx_test, x_test, padx_test], 1)\n",
    "    \n",
    "#     print(x_test_pad.shape)\n",
    "    \n",
    "#     pady_test = torch.zeros((ntest, data_points + 2*pad_size, pad_size, time_points, time_in))\n",
    "#     x_test_pad = torch.cat([pady_test, x_test_pad, pady_test], 2)\n",
    "\n",
    "    x_in_train = F.pad(x_in_train, (0, 0, 0, pad_size), mode = 'constant', value = 0)\n",
    "    \n",
    "    x_in_test = F.pad(x_in_test, (0, 0, 0, pad_size), mode = 'constant', value = 0)\n",
    "    \n",
    "#     print(x_in_train.shape)\n",
    "#     print(x_in_test.shape)\n",
    "    \n",
    "    gridx_pad = torch.tensor(np.linspace(0,1,S), dtype = torch.float)\n",
    "    gridx_pad = gridx_pad.reshape(1, S, 1, 1, 1).repeat([1, 1, S, T-T_in+pad_size, 1])\n",
    "    \n",
    "#     print(gridx_pad.shape)\n",
    "    \n",
    "    gridy_pad = torch.tensor(np.linspace(0, 1, S), dtype = torch.float)\n",
    "    gridy_pad = gridy_pad.reshape(1, 1, S, 1, 1).repeat([1, S, 1, T-T_in+pad_size, 1])\n",
    "    \n",
    "#     print(gridy_pad.shape)\n",
    "    \n",
    "    gridt_pad = torch.tensor(np.linspace(0,(T-T_in+pad_size)/(T-T_in),T-T_in+pad_size), dtype = torch.float)\n",
    "    gridt_pad = gridt_pad.reshape(1, 1, 1, T-T_in+pad_size, 1).repeat([1, S, S, 1, 1])\n",
    "    \n",
    "#     print(gridt_pad.shape)\n",
    "    \n",
    "    x_train_pad = torch.cat((gridx_pad.repeat([ntrain, 1, 1, 1, 1]), gridy_pad.repeat([ntrain,1,1,1,1]),\n",
    "                                gridt_pad.repeat([ntrain,1,1,1,1]), x_in_train), dim = -1)\n",
    "    \n",
    "    x_test_pad = torch.cat((gridx_pad.repeat([ntest, 1, 1, 1, 1]), gridy_pad.repeat([ntest,1,1,1,1]),\n",
    "                                gridt_pad.repeat([ntest,1,1,1,1]), x_in_test), dim = -1)\n",
    "    \n",
    "#     print(x_train_pad.shape)\n",
    "#     print(x_test_pad.shape)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train_pad, y_train), batch_size = batch_size, shuffle = True)\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test_pad, y_test), batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "173f363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, scheduler, l2_loss, epoch):\n",
    "    model.train()\n",
    "    start_time = time.perf_counter()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        # remove padding\n",
    "        output = output.narrow(3, 0, T-T_in)\n",
    "        \n",
    "        # loss = F.mse_loss(output.view(batch_size,-1), target.view(batch_size,-1), reduction = 'sum')\n",
    "        loss = l2_loss(output.view(batch_size, S, S, T-T_in), target.view(batch_size, S, S, T-T_in))\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    return total_loss / ntrain\n",
    "\n",
    "\n",
    "def test(test_loader, model, l2_loss):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    start_time = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "\n",
    "            # remove padding\n",
    "            output = output.narrow(3, 0, T-T_in)\n",
    "            \n",
    "            # loss += F.mse_loss(output.view(batch_size, -1), target.view(batch_size,-1), reduction = 'sum').item()\n",
    "            loss += l2_loss(output.view(batch_size, S, S, T-T_in), target.view(batch_size, S, S, T-T_in)).item()\n",
    "    \n",
    "    return loss / ntest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cbb132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad: 0\n",
      "Run: 1\n",
      "0 0.0703931986913085\n",
      "Run: 2\n",
      "1 0.06969555867835879\n",
      "Run: 3\n",
      "2 0.07010534325614572\n",
      "Run: 4\n",
      "3 0.07104938497766852\n",
      "Run: 5\n",
      "4 0.07194597948342561\n",
      "Run: 6\n",
      "5 0.06954790160059929\n",
      "Run: 7\n",
      "6 0.07055931320413947\n",
      "Run: 8\n",
      "7 0.06867981670424342\n",
      "Run: 9\n",
      "8 0.06952193170785904\n",
      "Run: 10\n",
      "9 0.07126401584595442\n",
      "Pad Result:0 0.07027624441497028\n",
      "Pad: 5\n",
      "Run: 1\n",
      "0 0.0628487335331738\n",
      "Run: 2\n",
      "1 0.06279926678165794\n",
      "Run: 3\n",
      "2 0.06439180942252279\n",
      "Run: 4\n",
      "3 0.06274582197889686\n",
      "Run: 5\n",
      "4 0.06391759179532527\n",
      "Run: 6\n",
      "5 0.06276385659351945\n",
      "Run: 7\n",
      "6 0.061991903278976676\n",
      "Run: 8\n",
      "7 0.06375059578567743\n",
      "Run: 9\n",
      "8 0.06298613917082548\n",
      "Run: 10\n",
      "9 0.0668746517971158\n",
      "Pad Result:5 0.06350703701376915\n",
      "Pad: 10\n",
      "Run: 1\n",
      "0 0.06146088911220431\n",
      "Run: 2\n",
      "1 0.06090684421360493\n",
      "Run: 3\n",
      "2 0.06297650223597884\n",
      "Run: 4\n",
      "3 0.06309385614469648\n",
      "Run: 5\n",
      "4 0.06286335764452815\n",
      "Run: 6\n",
      "5 0.06183585157617927\n",
      "Run: 7\n",
      "6 0.061422343850135806\n",
      "Run: 8\n",
      "7 0.06040159972384572\n",
      "Run: 9\n",
      "8 0.061048621516674756\n",
      "Run: 10\n",
      "9 0.06252929534763098\n",
      "Pad Result:10 0.06185391613654793\n",
      "Pad: 15\n",
      "Run: 1\n",
      "0 0.06168778877705336\n",
      "Run: 2\n",
      "1 0.059963033013045786\n",
      "Run: 3\n",
      "2 0.062006355337798594\n",
      "Run: 4\n",
      "3 0.06017341071739793\n",
      "Run: 5\n",
      "4 0.05852221949025989\n",
      "Run: 6\n",
      "5 0.059327695537358525\n",
      "Run: 7\n",
      "6 0.05964098814874887\n",
      "Run: 8\n",
      "7 0.06049641096964478\n",
      "Run: 9\n",
      "8 0.06063513938337564\n",
      "Run: 10\n",
      "9 0.06191267691552639\n",
      "Pad Result:15 0.06043657182902097\n",
      "Pad: 20\n",
      "Run: 1\n",
      "0 0.06001434300094843\n",
      "Run: 2\n",
      "1 0.060722652338445184\n",
      "Run: 3\n",
      "2 0.059613215047866104\n",
      "Run: 4\n",
      "3 0.05885213462635875\n",
      "Run: 5\n",
      "4 0.05938505275174975\n",
      "Run: 6\n",
      "5 0.057417473644018176\n",
      "Run: 7\n",
      "6 0.060372039396315816\n",
      "Run: 8\n"
     ]
    }
   ],
   "source": [
    "train_loss_total = []\n",
    "test_loss_total = []\n",
    "\n",
    "# train_loss_total = np.empty(0)\n",
    "# test_loss_total = np.empty(0)\n",
    "\n",
    "for pad in range(0, max_pad, 5):\n",
    "    print(\"Pad: \" + str(pad))\n",
    "    \n",
    "    train_loss_pad = []\n",
    "    test_loss_pad = []\n",
    "    \n",
    "#     train_loss_pad = np.empty(0)\n",
    "#     test_loss_pad = np.empty(0)\n",
    "    \n",
    "    train_loader, test_loader = pad2D(x_train, x_test, pad)\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        print(\"Run: \" + str(run+1))\n",
    "        \n",
    "        train_loss_epoch = []\n",
    "        test_loss_epoch = []\n",
    "        \n",
    "#         train_loss_epoch = np.empty(1)\n",
    "#         test_loss_epoch = np.empty(1)\n",
    "        \n",
    "        model = FNO3d(modes, modes, modes, width).cuda()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = step_size, gamma = gamma)\n",
    "\n",
    "        l2_loss = LpLoss(size_average=True)\n",
    "        \n",
    "        test_loss_initial = test(test_loader, model, l2_loss)\n",
    "        \n",
    "        test_loss_epoch.append(test_loss_initial)\n",
    "        \n",
    "#         np.append(test_loss_epoch, test_loss_initial, axis = 0)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # print(\"Epoch: \"+str(epoch))\n",
    "            \n",
    "            train_loss = train(train_loader, model, optimizer, scheduler, l2_loss, epoch)\n",
    "            \n",
    "            train_loss_epoch.append(train_loss)\n",
    "            \n",
    "#             np.append(train_loss_epoch, train_loss, axis = 0)\n",
    "            \n",
    "            test_loss = test(test_loader, model, l2_loss)\n",
    "            \n",
    "            test_loss_epoch.append(test_loss)\n",
    "            \n",
    "#             np.append(test_loss_epoch, test_loss, axis = 0)\n",
    "\n",
    "        \n",
    "        train_loss_pad.append(train_loss_epoch)\n",
    "        test_loss_pad.append(test_loss_epoch)\n",
    "        \n",
    "#         np.append(train_loss_pad, train_loss_epoch, axis = 0)\n",
    "#         np.append(test_loss_pad, test_loss_epoch, axis = 0)\n",
    "        \n",
    "        print(run, test_loss_epoch[-1])\n",
    "    \n",
    "    train_loss_total.append(train_loss_pad)\n",
    "    test_loss_total.append(test_loss_pad)\n",
    "    \n",
    "#     np.append(train_loss_total, train_loss_pad, axis = 0)\n",
    "#     np.append(test_loss_total, test_loss_pad, axis = 0)\n",
    "    \n",
    "#     print(np.array(test_loss_total).shape)\n",
    "    print(\"Pad Result:\" + str(pad) + \" \" + str(np.mean(np.array(test_loss_total)[-1,:,-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae6ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ns_train_loss'+\"_\"+str(epochs)+\"_\"+str(step_size), train_loss_total)\n",
    "np.save('ns_test_loss'+\"_\"+str(epochs)+\"_\"+str(step_size), test_loss_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b2c891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
